# -*- coding: utf-8 -*-
"""red neuronal.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/132_2vBylvRKpbWLexnLhso_LjiuKij5-

# Red neuronal (Covid en bolivia casos diarios)
"""

#Importamos librerias y obtenemos el dataset
#Importacion de librerias
import pandas as pd
import numpy as np
from keras.models import Sequential
from keras.layers import Dense
#Fijar semillas aleatorias para reproducibilidad
np.random.seed(7)
#Obteniendo el dataset
dataset = pd.read_csv('bolivia_covid19_cases_daily.csv')
#Creando una copia del dataset
df = pd.DataFrame(dataset)

"""##Transformacion de datos

Se obtiene las filas con los "casos, recuperados, muertes" y "activos"
"""

# Preprocesamiento de datos
# Eliminamos filas que tengan valores NaN (nulos)
df.dropna(axis=0, inplace=True) #Columnas, Guardar cambios
x = df.iloc[:,2:5].values
y = df.iloc[:,6:7].values

#Reformamos x e y 
#x = x.values.reshape(x.values.shape[0],1)
#y = y.values.reshape(y.values.shape[0],1)
print(y)
print(x)

"""## Preprocesamiento de datos
Convertir a las mismas dimensiones (Todos los valores estaran entre (0,1))
"""

#Preprocesamiento con MinMaxScaler
#Llevar a "x" y "y" a dimensiones de 1 y 0
from sklearn import preprocessing
escaler = preprocessing.MinMaxScaler()
x_escalado = escaler.fit_transform(x)
y_escalado = escaler.fit_transform(y)

print(x_escalado)
#print(y_escalado)

"""##Divicion de datos para entrenamiento y test"""

#Dividir datos para entrenamiento
from sklearn.model_selection import train_test_split
#Se divide los datos para el entrenamiento y test con test_size = 0.2 lo que recomienda el lic
X_train, X_test, y_train, y_test = train_test_split(x_escalado,y_escalado,test_size=0.2, random_state=0) #El orden debe ser el mismo en todos

"""##Creacion del modelo de red neuronal
3>10>10>1
"""

# Se crea el modelo y se agrega neuronas
modelo = Sequential()
modelo.add(Dense(10, input_shape=(3,), activation='relu'))
modelo.add(Dense(10, activation='relu'))
modelo.add(Dense(1, activation='sigmoid'))

#Compilamos el modelo
modelo.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
#Ajustamos el modelo entrenamos
modelo.fit(X_train, y_train, batch_size=10, epochs=100, verbose=1 )
#Evaluamos el modelo
score = modelo.evaluate(X_test, y_test)
print("\n%s: %.2f%%" % (modelo.metrics_names[1], score[1]*100))

#Mostrar matriz de confusion
'''y_pred = modelo.predict(X_test)
from sklearn.metrics import confusion_matrix
matriz = confusion_matrix(y_test, y_pred)
print(matriz)'''